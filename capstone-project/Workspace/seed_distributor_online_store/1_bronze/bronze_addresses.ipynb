{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5e99151-0db3-4a1f-9958-8f80ebd8131d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('/Workspace/Repos/zhastay_yeltay@epam.com/utils/'))\n",
    "\n",
    "from delta.tables import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from init import *\n",
    "init_spark()\n",
    "\n",
    "from util_logger import init_logger\n",
    "dbutils.widgets.text('task', \"test_logger\")\n",
    "logger = init_logger(dbutils.widgets.get('task'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7af08da7-d707-4696-8d0d-098ae4d5e6be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "457b6828-751c-4006-880c-8c3b29aed968",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bronze_addresses:Initializing Spark session.\nINFO:bronze_addresses:Reading updated addresses data.\nINFO:bronze_addresses:Accessing Delta table for addresses.\nINFO:bronze_addresses:Starting merge operation.\nINFO:bronze_addresses:Merge operation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize Spark session\n",
    "    logger.info(\"Initializing Spark session.\")\n",
    "\n",
    "    # Read addresses data\n",
    "    logger.info(\"Reading updated addresses data from %s.\", f\"{source_path}/addresses/\")\n",
    "    addresses_df_upd = spark.read.parquet(f\"{source_path}/addresses/\")\n",
    "\n",
    "    # Accessing Delta table\n",
    "    logger.info(\"Accessing Delta table for addresses at %s.\", f\"{bronze}/addresses/\")\n",
    "    addresses_df_raw = DeltaTable.forPath(spark, f\"{bronze}/addresses/\")\n",
    "    \n",
    "    # Log beginning of merge process\n",
    "    logger.info(\"Starting merge operation for addresses.\")\n",
    "    addresses_df_raw.alias(\"addresses\").merge(\n",
    "        addresses_df_upd.alias(\"updates\"), \"addresses.id = updates.id\"\n",
    "    ).whenMatchedUpdate(\n",
    "        condition=\"\"\"\n",
    "                addresses.createdOn != updates.createdOn\n",
    "                OR addresses.city != updates.city\n",
    "                OR addresses.state != updates.state\n",
    "                OR addresses.country != updates.country\n",
    "                OR addresses.addressline != updates.addressline\n",
    "            \"\"\",\n",
    "        set={\n",
    "            \"createdOn\": \"updates.createdOn\",\n",
    "            \"city\": \"updates.city\",\n",
    "            \"state\": \"updates.state\",\n",
    "            \"country\": \"updates.country\",\n",
    "            \"addressline\": \"updates.addressline\",\n",
    "        },\n",
    "    ).whenNotMatchedInsert(\n",
    "        values={\n",
    "            \"createdOn\": \"updates.createdOn\",\n",
    "            \"city\": \"updates.city\",\n",
    "            \"state\": \"updates.state\",\n",
    "            \"country\": \"updates.country\",\n",
    "            \"id\": \"updates.id\",\n",
    "            \"addressline\": \"updates.addressline\",\n",
    "        }\n",
    "    ).execute()\n",
    "    \n",
    "    # Log successful completion of merge process\n",
    "    logger.info(\"Merge operation for addresses completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Log any exceptions that occur\n",
    "    logger.error(\"An error occurred during the merge process for addresses.\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99a90582-07cf-491f-a2fc-f5d2a4704942",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "1945317b-526c-43e1-8c53-95c26b5344d6",
     "origId": 328367940062534,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2866688011324414,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_addresses",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
