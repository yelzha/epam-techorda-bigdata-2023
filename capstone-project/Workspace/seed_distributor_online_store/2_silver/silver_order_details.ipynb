{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14a65da6-71c4-4fef-b8e6-fb9db593b34a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('/Workspace/Repos/zhastay_yeltay@epam.com/utils/'))\n",
    "\n",
    "from delta.tables import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, DateType, LongType\n",
    "\n",
    "from init import *\n",
    "from udfs import * \n",
    "init_spark()\n",
    "\n",
    "from util_logger import init_logger\n",
    "dbutils.widgets.text('task', \"test_logger\")\n",
    "logger = init_logger(dbutils.widgets.get('task'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7abeb4cc-d4ad-4ea7-b138-2de9aeb0d3ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Log loading data from the bronze layer\n",
    "    logger.info(f\"Loading order details data from the Delta table at {bronze}/order_details.\")\n",
    "    bronze_order_details_df = spark.read.format(\"delta\").load(f\"{bronze}/order_details\")\n",
    "\n",
    "    # Log start of data transformation\n",
    "    logger.info(\"Starting transformation and validation of order details data.\")\n",
    "    silver_order_details_df_upd = (\n",
    "        bronze_order_details_df.withColumnsRenamed({\n",
    "            \"OrderId\": \"order_id\",\n",
    "            \"ItemId\": \"item_id\",\n",
    "            \"Quantity\": \"quantity\"\n",
    "        })\n",
    "        .withColumn(\n",
    "            \"is_valid\",\n",
    "            F.col(\"order_id\").isNotNull()\n",
    "            & F.col(\"item_id\").isNotNull()\n",
    "            & F.col(\"quantity\").isNotNull()\n",
    "            & (F.col(\"quantity\") > 0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Check for invalid entries and log the result\n",
    "    has_invalid = silver_order_details_df_upd.filter(~F.col('is_valid')).limit(1).count() > 0\n",
    "    logger.info(f\"Invalid entries found: {has_invalid}\")\n",
    "\n",
    "    # Filtering and aggregating valid entries\n",
    "    logger.info(\"Aggregating valid order details entries.\")\n",
    "    silver_order_details_df_upd = (\n",
    "        silver_order_details_df_upd\n",
    "        .groupBy(F.col(\"order_id\"), F.col(\"item_id\"))\n",
    "        .agg(F.sum(F.col(\"quantity\")).alias(\"quantity\"))\n",
    "    )\n",
    "\n",
    "    # Log start of the merge operation into the silver layer\n",
    "    logger.info(\"Starting merge operation for order details into the Silver layer.\")\n",
    "    silver_order_details_df = DeltaTable.forPath(spark, f\"{silver}/order_details/\")\n",
    "    silver_order_details_df.alias(\"order_details\").merge(\n",
    "        silver_order_details_df_upd.alias(\"updates\"),\n",
    "        \"order_details.order_id = updates.order_id AND order_details.item_id = updates.item_id\"\n",
    "    ).whenMatchedUpdate(\n",
    "        condition=\"order_details.quantity != updates.quantity\",\n",
    "        set={\"quantity\": \"updates.quantity\"}\n",
    "    ).whenNotMatchedInsert(\n",
    "        values={\n",
    "            \"order_id\": \"updates.order_id\",\n",
    "            \"item_id\": \"updates.item_id\",\n",
    "            \"quantity\": \"updates.quantity\"\n",
    "        }\n",
    "    ).execute()\n",
    "\n",
    "    # Log successful completion of the merge operation\n",
    "    logger.info(\"Merge operation completed successfully for order details.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(\"An error occurred during the processing and merging of order details data.\", exc_info=True)\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 862968690661588,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_order_details",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
