{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3463ae9-fe84-4255-b892-d56b496d46ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('/Workspace/Repos/zhastay_yeltay@epam.com/utils/'))\n",
    "\n",
    "from delta.tables import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, DateType, LongType\n",
    "\n",
    "from init import *\n",
    "from udfs import * \n",
    "init_spark()\n",
    "\n",
    "from util_logger import init_logger\n",
    "dbutils.widgets.text('task', \"test_logger\")\n",
    "logger = init_logger(dbutils.widgets.get('task'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7abeb4cc-d4ad-4ea7-b138-2de9aeb0d3ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    # Log the loading of data from the bronze layer\n",
    "    logger.info(f\"Loading item data from the Delta table at {bronze}/items.\")\n",
    "    bronze_items_df = (\n",
    "        spark.read.format(\"delta\").load(f\"{bronze}/items\")\n",
    "    )\n",
    "\n",
    "    # Log the start of data transformation\n",
    "    logger.info(\"Starting transformation and validation of item data.\")\n",
    "    silver_items_df_upd = (\n",
    "        bronze_items_df\n",
    "        .withColumnsRenamed({\n",
    "            \"Codes\": \"codes\",\n",
    "            \"Descriptions\": \"descriptions\"\n",
    "        })\n",
    "        .withColumn(\n",
    "            \"is_valid\",\n",
    "            F.when(\n",
    "                F.col(\"codes\").isNotNull()\n",
    "                & F.col(\"descriptions\").isNotNull()\n",
    "                & F.col(\"id\").isNotNull()\n",
    "                & F.col(\"price\").isNotNull()\n",
    "                & (F.length(F.col('codes')) == 10)\n",
    "                & (F.length(F.col('descriptions')) > 0)\n",
    "                & (F.col(\"price\") > 0),\n",
    "                True,\n",
    "            ).otherwise(False),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Check for invalid items and log the result\n",
    "    has_invalid = silver_items_df_upd.filter(~F.col('is_valid')).limit(1).count() > 0\n",
    "    logger.info(f\"Invalid entries found: {has_invalid}\")\n",
    "\n",
    "    # Log the start of the merge operation\n",
    "    logger.info(\"Starting merge operation for item data into the Silver layer.\")\n",
    "    silver_items_df = DeltaTable.forPath(spark, f\"{silver}/items/\")\n",
    "    silver_items_df.alias(\"items\").merge(\n",
    "        silver_items_df_upd.alias(\"updates\"), \"items.id = updates.id\"\n",
    "    ).whenMatchedUpdate(\n",
    "        condition=\"\"\"\n",
    "                items.codes != updates.codes\n",
    "                OR items.descriptions != updates.descriptions\n",
    "                OR items.price != updates.price\n",
    "            \"\"\",\n",
    "        set={\n",
    "            \"codes\": \"updates.codes\",\n",
    "            \"descriptions\": \"updates.descriptions\",\n",
    "            \"price\": \"updates.price\"\n",
    "        }\n",
    "    ).whenNotMatchedInsert(\n",
    "        values={\n",
    "            \"codes\": \"updates.codes\",\n",
    "            \"descriptions\": \"updates.descriptions\",\n",
    "            \"id\": \"updates.id\",\n",
    "            \"price\": \"updates.price\"\n",
    "        }\n",
    "    ).execute()\n",
    "\n",
    "    # Log successful completion of the merge operation\n",
    "    logger.info(\"Merge operation completed successfully for item data.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(\"An error occurred during the processing and merging of item data.\", exc_info=True)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14cd73a9-68db-4f2c-8a8e-c45915a3f0cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1655979001493758,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_items",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
