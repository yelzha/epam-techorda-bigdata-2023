{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f9fe6a7-b923-48f5-b1dd-ffa55e31d161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('/Workspace/Repos/zhastay_yeltay@epam.com/utils/'))\n",
    "\n",
    "from delta.tables import *\n",
    "\n",
    "from init import *\n",
    "init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9709645-1458-46ec-b0de-4ce6808375da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# file_path = '/tmp/zhastay_yeltay_log.log'\n",
    "# if os.path.exists(file_path):\n",
    "#     os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1791e77f-bdee-4bc9-8166-eb1ef338729a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "try:\n",
    "\n",
    "    # Step 1: Read the entire log file as a single string\n",
    "    with open('/tmp/zhastay_yeltay_log.log', 'r') as file:\n",
    "        log_content = file.read()\n",
    "\n",
    "    # Step 2: Define a regex pattern to identify the start of each log entry\n",
    "    # Assuming the log starts with a date in the format 'dd/mm/yyyy hh:mm:ss'\n",
    "    log_entry_pattern = re.compile(r'\\d{2}/\\d{2}/\\d{4} \\d{2}:\\d{2}:\\d{2}↭')\n",
    "\n",
    "    # Step 3: Find all matches and their positions in the file\n",
    "    matches = list(log_entry_pattern.finditer(log_content))\n",
    "\n",
    "    # Step 4: Split the content into log entries based on these positions\n",
    "    logs = []\n",
    "    start = 0\n",
    "    for match in matches:\n",
    "        end = match.start()\n",
    "        if end != 0:\n",
    "            logs.append(log_content[start:end])  # Append the log entry from the previous match to the current match\n",
    "        start = end\n",
    "\n",
    "    # Append the last log entry\n",
    "    logs.append(log_content[start:])\n",
    "\n",
    "    # Step 5: Create a DataFrame from the list of logs\n",
    "    df_pandas = pd.DataFrame([x.split('↭', 3) for x in logs if x.strip() != ''], columns=['log_date', 'task_name', 'log_level', 'log_message'])\n",
    "\n",
    "    df_spark = spark.createDataFrame(df_pandas)\n",
    "\n",
    "    df_spark.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"append\").saveAsTable(f'{catalog_name}.{schema_silver_name}.logs')\n",
    "\n",
    "    with open('/tmp/zhastay_yeltay_log.log', 'w') as f:\n",
    "        f.write('')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22d5cdbf-daf6-40bc-b10a-dd7201bb4741",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>log_date</th><th>task_name</th><th>log_level</th><th>log_message</th></tr></thead><tbody><tr><td>15/05/2024 03:50:15</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 14_daily_orders_by_city has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:50:10</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 13_customer_total_order_delivered has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:50:10</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 14_daily_orders_by_city.\n",
       "</td></tr><tr><td>15/05/2024 03:49:50</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 13_customer_total_order_delivered.\n",
       "</td></tr><tr><td>15/05/2024 03:49:49</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 12_affiliate_customer_orders has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:49:07</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 11_monthly_orders_by_state has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:49:07</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 12_affiliate_customer_orders.\n",
       "</td></tr><tr><td>15/05/2024 03:49:00</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 10_complete_order_customer_by_id has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:49:00</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 11_monthly_orders_by_state.\n",
       "</td></tr><tr><td>15/05/2024 03:48:55</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 10_complete_order_customer_by_id.\n",
       "</td></tr><tr><td>15/05/2024 03:48:54</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 09_total_orders_by_state_capital has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:30</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 09_total_orders_by_state_capital.\n",
       "</td></tr><tr><td>15/05/2024 03:48:29</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 08_order_delays_by_order_type has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:23</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 07_average_time_and_order_count_by_city has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:23</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 08_order_delays_by_order_type.\n",
       "</td></tr><tr><td>15/05/2024 03:48:19</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 06_total_vip_customers_coupon has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:19</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 07_average_time_and_order_count_by_city.\n",
       "</td></tr><tr><td>15/05/2024 03:48:15</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 05_affiliate_by_weekly_orders has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:15</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 06_total_vip_customers_coupon.\n",
       "</td></tr><tr><td>15/05/2024 03:48:11</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 04_customer_kinds_types_list has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:11</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 05_affiliate_by_weekly_orders.\n",
       "</td></tr><tr><td>15/05/2024 03:48:08</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 04_customer_kinds_types_list.\n",
       "</td></tr><tr><td>15/05/2024 03:48:07</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 03_total_customers_by_type_status has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:02</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 02_total_orders_by_address has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:48:02</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 03_total_customers_by_type_status.\n",
       "</td></tr><tr><td>15/05/2024 03:47:58</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation completed successfully. Table 01_cities_by_vip_customer_count has been populated/updated and overwritten successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:47:58</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 02_total_orders_by_address.\n",
       "</td></tr><tr><td>15/05/2024 03:47:57</td><td>gold_annex_processing</td><td>INFO</td><td>SQL operation started to populate/update the table 01_cities_by_vip_customer_count.\n",
       "</td></tr><tr><td>15/05/2024 03:47:42</td><td>silver_order_details</td><td>INFO</td><td>Merge operation completed successfully for order details.\n",
       "</td></tr><tr><td>15/05/2024 03:46:42</td><td>silver_address_dlq</td><td>INFO</td><td>DLQ has been successfully updated. Valid entries deleted and unprocessed entries marked as processed.\n",
       "</td></tr><tr><td>15/05/2024 03:46:28</td><td>silver_address_dlq</td><td>INFO</td><td>Merge operation for validated DLQ entries completed successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:46:28</td><td>silver_address_dlq</td><td>INFO</td><td>Accessing the DLQ Delta table to update entries.\n",
       "</td></tr><tr><td>15/05/2024 03:46:28</td><td>silver_address_dlq</td><td>INFO</td><td>Starting merge operation to delete valid entries from the DLQ and update remaining entries.\n",
       "</td></tr><tr><td>15/05/2024 03:46:17</td><td>silver_address_dlq</td><td>INFO</td><td>Loading DLQ Delta table from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses_dlq.\n",
       "</td></tr><tr><td>15/05/2024 03:46:17</td><td>silver_address_dlq</td><td>INFO</td><td>Starting to process unprocessed DLQ entries.\n",
       "</td></tr><tr><td>15/05/2024 03:46:17</td><td>silver_address_dlq</td><td>INFO</td><td>Processed DLQ.\n",
       "</td></tr><tr><td>15/05/2024 03:46:17</td><td>silver_address_dlq</td><td>INFO</td><td>Loading Silver Delta table for addresses from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses.\n",
       "</td></tr><tr><td>15/05/2024 03:46:17</td><td>silver_address_dlq</td><td>INFO</td><td>Starting merge operation for validated DLQ entries into the main Silver addresses table.\n",
       "</td></tr><tr><td>15/05/2024 03:46:01</td><td>silver_addresses_partly</td><td>INFO</td><td>Merge operation for invalid addresses completed successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:45:13</td><td>silver_order_details</td><td>INFO</td><td>Invalid entries found: False\n",
       "</td></tr><tr><td>15/05/2024 03:45:13</td><td>silver_order_details</td><td>INFO</td><td>Aggregating valid order details entries.\n",
       "</td></tr><tr><td>15/05/2024 03:45:13</td><td>silver_order_details</td><td>INFO</td><td>Starting merge operation for order details into the Silver layer.\n",
       "</td></tr><tr><td>15/05/2024 03:45:12</td><td>silver_order_details</td><td>INFO</td><td>Loading order details data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/order_details.\n",
       "</td></tr><tr><td>15/05/2024 03:45:12</td><td>silver_order_details</td><td>INFO</td><td>Starting transformation and validation of order details data.\n",
       "</td></tr><tr><td>15/05/2024 03:45:05</td><td>silver_addresses_partly</td><td>INFO</td><td>Invalid addresses found, processing them into DLQ (Dead Letter Queue).\n",
       "</td></tr><tr><td>15/05/2024 03:45:05</td><td>silver_addresses_partly</td><td>INFO</td><td>Loading DLQ Delta table for addresses from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses_dlq.\n",
       "</td></tr><tr><td>15/05/2024 03:45:05</td><td>silver_addresses_partly</td><td>INFO</td><td>Starting merge operation for invalid addresses into DLQ.\n",
       "</td></tr><tr><td>15/05/2024 03:44:57</td><td>bronze_order_details</td><td>INFO</td><td>Merge operation for new records in order details executed successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:44:55</td><td>bronze_orders</td><td>INFO</td><td>Merge operation for orders executed successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:44:55</td><td>silver_addresses_partly</td><td>INFO</td><td>Merge operation completed successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:44:55</td><td>silver_addresses_partly</td><td>INFO</td><td>Checking for invalid addresses.\n",
       "</td></tr><tr><td>15/05/2024 03:44:52</td><td>silver_addresses_partly</td><td>INFO</td><td>Starting merge operation for validated addresses.\n",
       "</td></tr><tr><td>15/05/2024 03:44:51</td><td>silver_addresses_partly</td><td>INFO</td><td>Loading address data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/addresses.\n",
       "</td></tr><tr><td>15/05/2024 03:44:51</td><td>silver_addresses_partly</td><td>INFO</td><td>Starting transformation and validation of address data.\n",
       "</td></tr><tr><td>15/05/2024 03:44:51</td><td>silver_addresses_partly</td><td>INFO</td><td>Completed filtering of valid and invalid addresses.\n",
       "</td></tr><tr><td>15/05/2024 03:44:51</td><td>silver_addresses_partly</td><td>INFO</td><td>Loading Silver layer Delta table for addresses from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses.\n",
       "</td></tr><tr><td>15/05/2024 03:44:36</td><td>bronze_addresses</td><td>INFO</td><td>Merge operation for addresses completed successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:44:21</td><td>silver_states_extra_data</td><td>INFO</td><td>State capital cities data saved successfully to Delta table.\n",
       "</td></tr><tr><td>15/05/2024 03:44:19</td><td>silver_customers</td><td>INFO</td><td>Merge operation completed successfully for customer data.\n",
       "</td></tr><tr><td>15/05/2024 03:44:17</td><td>silver_items</td><td>INFO</td><td>Merge operation completed successfully for item data.\n",
       "</td></tr><tr><td>15/05/2024 03:44:16</td><td>silver_states_extra_data</td><td>INFO</td><td>Selecting city and state columns from the loaded data.\n",
       "</td></tr><tr><td>15/05/2024 03:44:16</td><td>silver_states_extra_data</td><td>INFO</td><td>Writing state capital cities data to Delta table hive_metastore.zhastay_yeltay_02_silver.state_capital_cities.\n",
       "</td></tr><tr><td>15/05/2024 03:44:15</td><td>silver_states_extra_data</td><td>INFO</td><td>Loading state capital cities data from JSON at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_capital_cities.json.\n",
       "</td></tr><tr><td>15/05/2024 03:44:14</td><td>silver_states_extra_data</td><td>INFO</td><td>Metropolitan cities data saved successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:44:13</td><td>silver_customers</td><td>INFO</td><td>Invalid entries found: False\n",
       "</td></tr><tr><td>15/05/2024 03:44:13</td><td>silver_customers</td><td>INFO</td><td>Starting merge operation for customer data into the Silver layer.\n",
       "</td></tr><tr><td>15/05/2024 03:44:10</td><td>silver_customers</td><td>INFO</td><td>Starting transformation of customer data.\n",
       "</td></tr><tr><td>15/05/2024 03:44:10</td><td>silver_items</td><td>INFO</td><td>Invalid entries found: False\n",
       "</td></tr><tr><td>15/05/2024 03:44:10</td><td>silver_items</td><td>INFO</td><td>Starting merge operation for item data into the Silver layer.\n",
       "</td></tr><tr><td>15/05/2024 03:44:09</td><td>silver_customers</td><td>INFO</td><td>Loading customer data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/customers.\n",
       "</td></tr><tr><td>15/05/2024 03:44:08</td><td>silver_items</td><td>INFO</td><td>Loading item data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/items.\n",
       "</td></tr><tr><td>15/05/2024 03:44:08</td><td>silver_items</td><td>INFO</td><td>Starting transformation and validation of item data.\n",
       "</td></tr><tr><td>15/05/2024 03:44:07</td><td>silver_states_extra_data</td><td>INFO</td><td>Number of metropolitans found: 387\n",
       "</td></tr><tr><td>15/05/2024 03:44:07</td><td>silver_states_extra_data</td><td>INFO</td><td>Writing metropolitan cities data to Delta table hive_metastore.zhastay_yeltay_02_silver.metropolitan_cities.\n",
       "</td></tr><tr><td>15/05/2024 03:44:05</td><td>silver_states_extra_data</td><td>INFO</td><td>Number of metropolitan cities found: 717\n",
       "</td></tr><tr><td>15/05/2024 03:44:02</td><td>silver_states_extra_data</td><td>INFO</td><td>State geocodes data prepared successfully for further processing.\n",
       "</td></tr><tr><td>15/05/2024 03:44:02</td><td>silver_states_extra_data</td><td>INFO</td><td>Starting to join statistical areas data with state geocodes.\n",
       "</td></tr><tr><td>15/05/2024 03:44:01</td><td>silver_states_extra_data</td><td>INFO</td><td>Converting pandas DataFrame to Spark DataFrame.\n",
       "</td></tr><tr><td>15/05/2024 03:44:01</td><td>silver_states_extra_data</td><td>INFO</td><td>Starting cleaning and filtering of statistical areas data.\n",
       "</td></tr><tr><td>15/05/2024 03:44:01</td><td>silver_states_extra_data</td><td>INFO</td><td>Statistical areas data prepared successfully for further processing.\n",
       "</td></tr><tr><td>15/05/2024 03:44:01</td><td>silver_states_extra_data</td><td>INFO</td><td>Reading state geocodes data from Excel file at /dbfs/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_geocodes.xlsx.\n",
       "</td></tr><tr><td>15/05/2024 03:44:01</td><td>silver_states_extra_data</td><td>INFO</td><td>Converting pandas DataFrame to Spark DataFrame and renaming columns.\n",
       "</td></tr><tr><td>15/05/2024 03:44:01</td><td>silver_states_extra_data</td><td>INFO</td><td>Filtering out records where state_code is 0.\n",
       "</td></tr><tr><td>15/05/2024 03:44:00</td><td>silver_states_extra_data</td><td>INFO</td><td>Reading statistical areas data from Excel file at /dbfs/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/statistical_areas.xlsx.\n",
       "</td></tr><tr><td>15/05/2024 03:43:59</td><td>bronze_customers</td><td>INFO</td><td>Merge operation executed successfully.\n",
       "</td></tr><tr><td>15/05/2024 03:43:59</td><td>bronze_items</td><td>INFO</td><td>Merge operation executed successfully for items data.\n",
       "</td></tr><tr><td>15/05/2024 03:43:43</td><td>bronze_customers</td><td>INFO</td><td>Accessed DeltaTable for raw customers data at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/customers/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:43</td><td>bronze_items</td><td>INFO</td><td>Accessed DeltaTable for raw items data at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/items/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:43</td><td>bronze_states_extra_data</td><td>INFO</td><td>Successfully copied statistical areas data from https://www2.census.gov/programs-surveys/metro-micro/geographies/reference-files/2023/delineation-files/list2_2023.xlsx to dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/statistical_areas.xlsx.\n",
       "</td></tr><tr><td>15/05/2024 03:43:43</td><td>bronze_states_extra_data</td><td>INFO</td><td>Successfully copied state capitals data from https://cdn.jsdelivr.net/npm/vega-datasets@v1.29.0/data/us-state-capitals.json to dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_capital_cities.json.\n",
       "</td></tr><tr><td>15/05/2024 03:43:43</td><td>bronze_states_extra_data</td><td>INFO</td><td>Completed all data download and storage operations.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_addresses</td><td>INFO</td><td>Initializing Spark session.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_addresses</td><td>INFO</td><td>Reading updated addresses data from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/addresses/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_states_extra_data</td><td>INFO</td><td>Starting data download and storage operations.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_addresses</td><td>INFO</td><td>Accessing Delta table for addresses at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/addresses/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_orders</td><td>INFO</td><td>Updated orders data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/orders/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_order_details</td><td>INFO</td><td>Updated order details data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/orderDetails/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_customers</td><td>INFO</td><td>Updated customers data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/customers/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_items</td><td>INFO</td><td>Updated items data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/items/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_addresses</td><td>INFO</td><td>Starting merge operation for addresses.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_orders</td><td>INFO</td><td>Accessed DeltaTable for raw orders at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/orders/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_order_details</td><td>INFO</td><td>Accessed DeltaTable for raw order details at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/order_details/.\n",
       "</td></tr><tr><td>15/05/2024 03:43:42</td><td>bronze_states_extra_data</td><td>INFO</td><td>Successfully copied state geocodes from https://www2.census.gov/programs-surveys/popest/geographies/2022/state-geocodes-v2022.xlsx to dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_geocodes.xlsx.\n",
       "</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "15/05/2024 03:50:15",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 14_daily_orders_by_city has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:50:10",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 13_customer_total_order_delivered has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:50:10",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 14_daily_orders_by_city.\n"
        ],
        [
         "15/05/2024 03:49:50",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 13_customer_total_order_delivered.\n"
        ],
        [
         "15/05/2024 03:49:49",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 12_affiliate_customer_orders has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:49:07",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 11_monthly_orders_by_state has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:49:07",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 12_affiliate_customer_orders.\n"
        ],
        [
         "15/05/2024 03:49:00",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 10_complete_order_customer_by_id has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:49:00",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 11_monthly_orders_by_state.\n"
        ],
        [
         "15/05/2024 03:48:55",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 10_complete_order_customer_by_id.\n"
        ],
        [
         "15/05/2024 03:48:54",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 09_total_orders_by_state_capital has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:30",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 09_total_orders_by_state_capital.\n"
        ],
        [
         "15/05/2024 03:48:29",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 08_order_delays_by_order_type has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:23",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 07_average_time_and_order_count_by_city has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:23",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 08_order_delays_by_order_type.\n"
        ],
        [
         "15/05/2024 03:48:19",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 06_total_vip_customers_coupon has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:19",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 07_average_time_and_order_count_by_city.\n"
        ],
        [
         "15/05/2024 03:48:15",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 05_affiliate_by_weekly_orders has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:15",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 06_total_vip_customers_coupon.\n"
        ],
        [
         "15/05/2024 03:48:11",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 04_customer_kinds_types_list has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:11",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 05_affiliate_by_weekly_orders.\n"
        ],
        [
         "15/05/2024 03:48:08",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 04_customer_kinds_types_list.\n"
        ],
        [
         "15/05/2024 03:48:07",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 03_total_customers_by_type_status has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:02",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 02_total_orders_by_address has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:48:02",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 03_total_customers_by_type_status.\n"
        ],
        [
         "15/05/2024 03:47:58",
         "gold_annex_processing",
         "INFO",
         "SQL operation completed successfully. Table 01_cities_by_vip_customer_count has been populated/updated and overwritten successfully.\n"
        ],
        [
         "15/05/2024 03:47:58",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 02_total_orders_by_address.\n"
        ],
        [
         "15/05/2024 03:47:57",
         "gold_annex_processing",
         "INFO",
         "SQL operation started to populate/update the table 01_cities_by_vip_customer_count.\n"
        ],
        [
         "15/05/2024 03:47:42",
         "silver_order_details",
         "INFO",
         "Merge operation completed successfully for order details.\n"
        ],
        [
         "15/05/2024 03:46:42",
         "silver_address_dlq",
         "INFO",
         "DLQ has been successfully updated. Valid entries deleted and unprocessed entries marked as processed.\n"
        ],
        [
         "15/05/2024 03:46:28",
         "silver_address_dlq",
         "INFO",
         "Merge operation for validated DLQ entries completed successfully.\n"
        ],
        [
         "15/05/2024 03:46:28",
         "silver_address_dlq",
         "INFO",
         "Accessing the DLQ Delta table to update entries.\n"
        ],
        [
         "15/05/2024 03:46:28",
         "silver_address_dlq",
         "INFO",
         "Starting merge operation to delete valid entries from the DLQ and update remaining entries.\n"
        ],
        [
         "15/05/2024 03:46:17",
         "silver_address_dlq",
         "INFO",
         "Loading DLQ Delta table from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses_dlq.\n"
        ],
        [
         "15/05/2024 03:46:17",
         "silver_address_dlq",
         "INFO",
         "Starting to process unprocessed DLQ entries.\n"
        ],
        [
         "15/05/2024 03:46:17",
         "silver_address_dlq",
         "INFO",
         "Processed DLQ.\n"
        ],
        [
         "15/05/2024 03:46:17",
         "silver_address_dlq",
         "INFO",
         "Loading Silver Delta table for addresses from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses.\n"
        ],
        [
         "15/05/2024 03:46:17",
         "silver_address_dlq",
         "INFO",
         "Starting merge operation for validated DLQ entries into the main Silver addresses table.\n"
        ],
        [
         "15/05/2024 03:46:01",
         "silver_addresses_partly",
         "INFO",
         "Merge operation for invalid addresses completed successfully.\n"
        ],
        [
         "15/05/2024 03:45:13",
         "silver_order_details",
         "INFO",
         "Invalid entries found: False\n"
        ],
        [
         "15/05/2024 03:45:13",
         "silver_order_details",
         "INFO",
         "Aggregating valid order details entries.\n"
        ],
        [
         "15/05/2024 03:45:13",
         "silver_order_details",
         "INFO",
         "Starting merge operation for order details into the Silver layer.\n"
        ],
        [
         "15/05/2024 03:45:12",
         "silver_order_details",
         "INFO",
         "Loading order details data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/order_details.\n"
        ],
        [
         "15/05/2024 03:45:12",
         "silver_order_details",
         "INFO",
         "Starting transformation and validation of order details data.\n"
        ],
        [
         "15/05/2024 03:45:05",
         "silver_addresses_partly",
         "INFO",
         "Invalid addresses found, processing them into DLQ (Dead Letter Queue).\n"
        ],
        [
         "15/05/2024 03:45:05",
         "silver_addresses_partly",
         "INFO",
         "Loading DLQ Delta table for addresses from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses_dlq.\n"
        ],
        [
         "15/05/2024 03:45:05",
         "silver_addresses_partly",
         "INFO",
         "Starting merge operation for invalid addresses into DLQ.\n"
        ],
        [
         "15/05/2024 03:44:57",
         "bronze_order_details",
         "INFO",
         "Merge operation for new records in order details executed successfully.\n"
        ],
        [
         "15/05/2024 03:44:55",
         "bronze_orders",
         "INFO",
         "Merge operation for orders executed successfully.\n"
        ],
        [
         "15/05/2024 03:44:55",
         "silver_addresses_partly",
         "INFO",
         "Merge operation completed successfully.\n"
        ],
        [
         "15/05/2024 03:44:55",
         "silver_addresses_partly",
         "INFO",
         "Checking for invalid addresses.\n"
        ],
        [
         "15/05/2024 03:44:52",
         "silver_addresses_partly",
         "INFO",
         "Starting merge operation for validated addresses.\n"
        ],
        [
         "15/05/2024 03:44:51",
         "silver_addresses_partly",
         "INFO",
         "Loading address data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/addresses.\n"
        ],
        [
         "15/05/2024 03:44:51",
         "silver_addresses_partly",
         "INFO",
         "Starting transformation and validation of address data.\n"
        ],
        [
         "15/05/2024 03:44:51",
         "silver_addresses_partly",
         "INFO",
         "Completed filtering of valid and invalid addresses.\n"
        ],
        [
         "15/05/2024 03:44:51",
         "silver_addresses_partly",
         "INFO",
         "Loading Silver layer Delta table for addresses from dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_02_silver/addresses.\n"
        ],
        [
         "15/05/2024 03:44:36",
         "bronze_addresses",
         "INFO",
         "Merge operation for addresses completed successfully.\n"
        ],
        [
         "15/05/2024 03:44:21",
         "silver_states_extra_data",
         "INFO",
         "State capital cities data saved successfully to Delta table.\n"
        ],
        [
         "15/05/2024 03:44:19",
         "silver_customers",
         "INFO",
         "Merge operation completed successfully for customer data.\n"
        ],
        [
         "15/05/2024 03:44:17",
         "silver_items",
         "INFO",
         "Merge operation completed successfully for item data.\n"
        ],
        [
         "15/05/2024 03:44:16",
         "silver_states_extra_data",
         "INFO",
         "Selecting city and state columns from the loaded data.\n"
        ],
        [
         "15/05/2024 03:44:16",
         "silver_states_extra_data",
         "INFO",
         "Writing state capital cities data to Delta table hive_metastore.zhastay_yeltay_02_silver.state_capital_cities.\n"
        ],
        [
         "15/05/2024 03:44:15",
         "silver_states_extra_data",
         "INFO",
         "Loading state capital cities data from JSON at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_capital_cities.json.\n"
        ],
        [
         "15/05/2024 03:44:14",
         "silver_states_extra_data",
         "INFO",
         "Metropolitan cities data saved successfully.\n"
        ],
        [
         "15/05/2024 03:44:13",
         "silver_customers",
         "INFO",
         "Invalid entries found: False\n"
        ],
        [
         "15/05/2024 03:44:13",
         "silver_customers",
         "INFO",
         "Starting merge operation for customer data into the Silver layer.\n"
        ],
        [
         "15/05/2024 03:44:10",
         "silver_customers",
         "INFO",
         "Starting transformation of customer data.\n"
        ],
        [
         "15/05/2024 03:44:10",
         "silver_items",
         "INFO",
         "Invalid entries found: False\n"
        ],
        [
         "15/05/2024 03:44:10",
         "silver_items",
         "INFO",
         "Starting merge operation for item data into the Silver layer.\n"
        ],
        [
         "15/05/2024 03:44:09",
         "silver_customers",
         "INFO",
         "Loading customer data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/customers.\n"
        ],
        [
         "15/05/2024 03:44:08",
         "silver_items",
         "INFO",
         "Loading item data from the Delta table at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/items.\n"
        ],
        [
         "15/05/2024 03:44:08",
         "silver_items",
         "INFO",
         "Starting transformation and validation of item data.\n"
        ],
        [
         "15/05/2024 03:44:07",
         "silver_states_extra_data",
         "INFO",
         "Number of metropolitans found: 387\n"
        ],
        [
         "15/05/2024 03:44:07",
         "silver_states_extra_data",
         "INFO",
         "Writing metropolitan cities data to Delta table hive_metastore.zhastay_yeltay_02_silver.metropolitan_cities.\n"
        ],
        [
         "15/05/2024 03:44:05",
         "silver_states_extra_data",
         "INFO",
         "Number of metropolitan cities found: 717\n"
        ],
        [
         "15/05/2024 03:44:02",
         "silver_states_extra_data",
         "INFO",
         "State geocodes data prepared successfully for further processing.\n"
        ],
        [
         "15/05/2024 03:44:02",
         "silver_states_extra_data",
         "INFO",
         "Starting to join statistical areas data with state geocodes.\n"
        ],
        [
         "15/05/2024 03:44:01",
         "silver_states_extra_data",
         "INFO",
         "Converting pandas DataFrame to Spark DataFrame.\n"
        ],
        [
         "15/05/2024 03:44:01",
         "silver_states_extra_data",
         "INFO",
         "Starting cleaning and filtering of statistical areas data.\n"
        ],
        [
         "15/05/2024 03:44:01",
         "silver_states_extra_data",
         "INFO",
         "Statistical areas data prepared successfully for further processing.\n"
        ],
        [
         "15/05/2024 03:44:01",
         "silver_states_extra_data",
         "INFO",
         "Reading state geocodes data from Excel file at /dbfs/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_geocodes.xlsx.\n"
        ],
        [
         "15/05/2024 03:44:01",
         "silver_states_extra_data",
         "INFO",
         "Converting pandas DataFrame to Spark DataFrame and renaming columns.\n"
        ],
        [
         "15/05/2024 03:44:01",
         "silver_states_extra_data",
         "INFO",
         "Filtering out records where state_code is 0.\n"
        ],
        [
         "15/05/2024 03:44:00",
         "silver_states_extra_data",
         "INFO",
         "Reading statistical areas data from Excel file at /dbfs/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/statistical_areas.xlsx.\n"
        ],
        [
         "15/05/2024 03:43:59",
         "bronze_customers",
         "INFO",
         "Merge operation executed successfully.\n"
        ],
        [
         "15/05/2024 03:43:59",
         "bronze_items",
         "INFO",
         "Merge operation executed successfully for items data.\n"
        ],
        [
         "15/05/2024 03:43:43",
         "bronze_customers",
         "INFO",
         "Accessed DeltaTable for raw customers data at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/customers/.\n"
        ],
        [
         "15/05/2024 03:43:43",
         "bronze_items",
         "INFO",
         "Accessed DeltaTable for raw items data at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/items/.\n"
        ],
        [
         "15/05/2024 03:43:43",
         "bronze_states_extra_data",
         "INFO",
         "Successfully copied statistical areas data from https://www2.census.gov/programs-surveys/metro-micro/geographies/reference-files/2023/delineation-files/list2_2023.xlsx to dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/statistical_areas.xlsx.\n"
        ],
        [
         "15/05/2024 03:43:43",
         "bronze_states_extra_data",
         "INFO",
         "Successfully copied state capitals data from https://cdn.jsdelivr.net/npm/vega-datasets@v1.29.0/data/us-state-capitals.json to dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_capital_cities.json.\n"
        ],
        [
         "15/05/2024 03:43:43",
         "bronze_states_extra_data",
         "INFO",
         "Completed all data download and storage operations.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_addresses",
         "INFO",
         "Initializing Spark session.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_addresses",
         "INFO",
         "Reading updated addresses data from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/addresses/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_states_extra_data",
         "INFO",
         "Starting data download and storage operations.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_addresses",
         "INFO",
         "Accessing Delta table for addresses at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/addresses/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_orders",
         "INFO",
         "Updated orders data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/orders/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_order_details",
         "INFO",
         "Updated order details data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/orderDetails/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_customers",
         "INFO",
         "Updated customers data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/customers/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_items",
         "INFO",
         "Updated items data read successfully from abfss://dex-data@dextestwesteurope.dfs.core.windows.net/data/adv-dse/items/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_addresses",
         "INFO",
         "Starting merge operation for addresses.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_orders",
         "INFO",
         "Accessed DeltaTable for raw orders at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/orders/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_order_details",
         "INFO",
         "Accessed DeltaTable for raw order details at dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/order_details/.\n"
        ],
        [
         "15/05/2024 03:43:42",
         "bronze_states_extra_data",
         "INFO",
         "Successfully copied state geocodes from https://www2.census.gov/programs-surveys/popest/geographies/2022/state-geocodes-v2022.xlsx to dbfs:/mnt/adls_custom/data/Team_B/zhastay_yeltay/zhastay_yeltay_01_bronze/state_geocodes.xlsx.\n"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 46
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "log_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "task_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "log_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "log_message",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "-- DELETE\n",
    "-- FROM hive_metastore.zhastay_yeltay_02_silver.logs\n",
    "-- WHERE job_name IS NULL;\n",
    "\n",
    "SELECT * FROM hive_metastore.zhastay_yeltay_02_silver.logs\n",
    "ORDER BY \n",
    "  log_date DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "200e12dc-8abe-40df-baf7-4ed5e24c5c36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1219948954308182,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "logging_process",
   "widgets": {
    "job": {
     "currentValue": "test",
     "nuid": "084bd92c-3d5b-454a-a2ea-6de308ea7b93",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "test",
      "label": null,
      "name": "job",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
